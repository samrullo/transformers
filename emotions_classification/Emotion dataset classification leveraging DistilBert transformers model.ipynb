{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4900a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e57c771",
   "metadata": {},
   "source": [
    "# Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5a55ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\amrul\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\emotion\\348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705 (last modified on Fri Mar 18 22:16:45 2022) since it couldn't be found locally at emotion., or remotely on the Hugging Face Hub.\n",
      "Using custom data configuration default\n",
      "Reusing dataset emotion (C:\\Users\\amrul\\.cache\\huggingface\\datasets\\emotion\\default\\0.0.0\\348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860dc7ebb0b5492e99d52e114406ebb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emotions=load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686ed122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore emotions dataset\n",
    "# It is a DatasetDict with keys like train, validation and test\n",
    "# Each of those is a Dataset with features, column names which are usually a text and a label\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd095e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the type of train_set['features']['label'] : <class 'datasets.features.features.ClassLabel'>\n",
      "label_feature.int2str(0) : sadness\n",
      "number of classes in label_feature : 6\n",
      "name of classes in label_feature : ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# I want to view textlabel of a text from emotions dataset\n",
    "# to do that first I get access to train_set.features.label which returns ClassLabel type\n",
    "# and from there I can use its int2str function\n",
    "\n",
    "train_set = emotions[\"train\"]\n",
    "label_feature = train_set.features[\"label\"]\n",
    "print(f\"the type of train_set['features']['label'] : {type(label_feature)}\")\n",
    "print(f\"label_feature.int2str(0) : {label_feature.int2str(0)}\")\n",
    "print(f\"number of classes in label_feature : {label_feature.num_classes}\")\n",
    "print(f\"name of classes in label_feature : {label_feature.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ba5d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_feature : Value(dtype='string', id=None)\n"
     ]
    }
   ],
   "source": [
    "text_feature = train_set.features[\"text\"]\n",
    "print(f\"text_feature : {text_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697fae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of train_text : <class 'list'>\n",
      "there are 16000 elements in train_texts\n",
      "first text in train_texts list : i didnt feel humiliated and its label : sadness\n"
     ]
    }
   ],
   "source": [
    "train_texts = train_set[\"text\"]\n",
    "print(f\"type of train_text : {type(train_texts)}\")\n",
    "print(f\"there are {len(train_texts)} elements in train_texts\")\n",
    "print(f\"first text in train_texts list : {train_texts[0]} and its label : {label_feature.int2str(train_set['label'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1841cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  i didn t feel very reassured by her tone but i understand this is a big shock and adjustment for everyone \n",
      " label :  joy\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_set=emotions[\"train\"]\n",
    "_random_idx=random.randint(0,len(train_set))\n",
    "_random_emotion_data=train_set[_random_idx]\n",
    "print(\"text : \",_random_emotion_data[\"text\"],\"\\n\",\"label : \",label_feature.int2str(_random_emotion_data[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64485c80",
   "metadata": {},
   "source": [
    "   # Import Tokenizer and DistilBert model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd43118",
   "metadata": {},
   "source": [
    "It is important to use the right pretrained tokenizer for a pretrained model. Otherwise pretrained token representations become obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda34857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca432d7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# We will use DistilBERT which is smaller version of BERT to classify emotion text\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\amrul\\pycharmprojects\\transformers\\venvpy\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:546\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\amrul\\pycharmprojects\\transformers\\venvpy\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1724\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1724\u001b[0m         resolved_vocab_files[file_id] \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m   1736\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m local_files_only:\n",
      "File \u001b[1;32mc:\\users\\amrul\\pycharmprojects\\transformers\\venvpy\\lib\\site-packages\\transformers\\file_utils.py:1921\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   1917\u001b[0m     local_files_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m   1920\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m-> 1921\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1927\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1928\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[0;32m   1933\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[1;32mc:\\users\\amrul\\pycharmprojects\\transformers\\venvpy\\lib\\site-packages\\transformers\\file_utils.py:2177\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   2171\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   2172\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find the requested files in the cached path and outgoing traffic has been\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2173\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m disabled. To enable model look-ups and downloads online, set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2174\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2175\u001b[0m                 )\n\u001b[0;32m   2176\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2178\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2179\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2180\u001b[0m                 )\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;66;03m# From now on, etag is not None.\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_download:\n",
      "\u001b[1;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "# We will use DistilBERT which is smaller version of BERT to classify emotion text\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4803ec",
   "metadata": {},
   "source": [
    "In a similar manner we can load transformer models of interest by passing model name to AutoModel.from_pretrained(<model_name>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4c2f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38305d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96fb58",
   "metadata": {},
   "source": [
    "Above we are checking if GPU is available. If not we are loading the model to CPU device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed1259",
   "metadata": {},
   "source": [
    "To warm up let's extract the last hidden states for a simple string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f47a3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In below example we are using tokenizer.encode to encode long text into a series of tokens which are bunch of ids\n",
    "# tokenizer.encode returns the result as a tensor\n",
    "# also we are loading that tensor to the device, CPU in this case\n",
    "text = \"NLP will completely transform our understanding of machines speaking a language. We will come into realization that machines can master language better than humans.\"\n",
    "tokens=tokenizer.encode(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b6a4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens : tensor([[  101, 17953,  2361,  2097,  3294, 10938,  2256,  4824,  1997,  6681,\n",
      "          4092,  1037,  2653,  1012,  2057,  2097,  2272,  2046, 12393,  2008,\n",
      "          6681,  2064,  3040,  2653,  2488,  2084,  4286,  1012,   102]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokens : {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f121268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 29])\n",
      "['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(tokens.shape)\n",
    "print(tokenizer.model_input_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd05a2d0",
   "metadata": {},
   "source": [
    "```return_tensors=\"pt\"``` ensures that we return token embeddings as PyTorch tensors and we load them into the same device as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "376d1cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 17953,  2361,  2097,  3294, 10938,  2256,  4824,  1997,  6681,\n",
       "          4092,  1037,  2653,  1012,  2057,  2097,  2272,  2046, 12393,  2008,\n",
       "          6681,  2064,  3040,  2653,  2488,  2084,  4286,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we call tokenizer and pass the text to it, it returns a dictionary with input_ids and attention_mask keys\n",
    "inputs=tokenizer(text, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc68656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(101) [CLS]\n",
      "tensor(17953) nl\n",
      "tensor(2361) ##p\n",
      "tensor(2097) will\n",
      "tensor(3294) completely\n",
      "tensor(10938) transform\n",
      "tensor(2256) our\n",
      "tensor(4824) understanding\n",
      "tensor(1997) of\n",
      "tensor(6681) machines\n",
      "tensor(4092) speaking\n",
      "tensor(1037) a\n",
      "tensor(2653) language\n",
      "tensor(1012) .\n",
      "tensor(2057) we\n",
      "tensor(2097) will\n",
      "tensor(2272) come\n",
      "tensor(2046) into\n",
      "tensor(12393) realization\n",
      "tensor(2008) that\n",
      "tensor(6681) machines\n",
      "tensor(2064) can\n",
      "tensor(3040) master\n",
      "tensor(2653) language\n",
      "tensor(2488) better\n",
      "tensor(2084) than\n",
      "tensor(4286) humans\n",
      "tensor(1012) .\n",
      "tensor(102) [SEP]\n"
     ]
    }
   ],
   "source": [
    "def view_tokens(tokenizer,tokens):\n",
    "    for token in tokens:\n",
    "        print(token,tokenizer.decode(token))\n",
    "\n",
    "view_tokens(tokenizer,tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78743f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 29, 768])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=model(tokens)\n",
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2664e6",
   "metadata": {},
   "source": [
    "Looking at the hidden states we can see it has the shape ```[batch_size,n_tokens,hid_dim]```. BERT generates a hidden state for each input token. Then it uses these hidden states to predict masked tokens. For classification tasks it is common to use the hidden state of [CLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c40cc",
   "metadata": {},
   "source": [
    "# Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada0506",
   "metadata": {},
   "source": [
    "```padding``` will pad each sequence with zeroes to the longest sequence in the batch. ```truncation``` will truncate at model's maximum context size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e020b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tokenizer,batch):\n",
    "    return tokenizer(batch[\"text\"],padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5890ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102], [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(tokenizer,emotions[\"train\"][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad95c5b",
   "metadata": {},
   "source": [
    "Above you will notice that batch tokenizer returns ```attention_masks``` in addition to ```input_ids```. This is necessary so that the model doesn't get confused with paddings and can ignore them when processing each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecb49422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\amrul\\.cache\\huggingface\\datasets\\emotion\\default\\0.0.0\\348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705\\cache-a2030fb1427d9b81.arrow\n",
      "Loading cached processed dataset at C:\\Users\\amrul\\.cache\\huggingface\\datasets\\emotion\\default\\0.0.0\\348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705\\cache-59c2c3f8ffffd72b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\amrul\\.cache\\huggingface\\datasets\\emotion\\default\\0.0.0\\348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705\\cache-67e9f09415f9a25a.arrow\n"
     ]
    }
   ],
   "source": [
    "emotions_encoded=emotions.map(lambda batch : tokenize(tokenizer,batch),batched=True,batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace1029",
   "metadata": {},
   "source": [
    "By default ```DatasetDict.map``` operates on operates individually on every example in the corpus, so setting ```batched=True``` will encode the tweets in batches, while ```batch_size=None``` applies ```tokenize``` in one single batch and ensures that input tensors and attention masks have the same shape globally. We can confirm that this operation added two new features to the dataset ```input_ids``` and ```attention_masks```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c6bf913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_encoded[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e77be",
   "metadata": {},
   "source": [
    "We can pass ```input_ids``` and ```attention_mask``` to the model in a below manner if we had single example. Notice we have to convert them into PyTorch tensors before passing them into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "097bca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 87, 768])\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_set=emotions_encoded[\"train\"]\n",
    "train_set.features\n",
    "input_ids=train_set['input_ids']\n",
    "attention_mask=train_set[\"attention_mask\"]\n",
    "with torch.no_grad():\n",
    "    output=model(torch.tensor(input_ids[:5]),torch.tensor(attention_mask[:5]))\n",
    "last_hidden_state=output.last_hidden_state\n",
    "print(last_hidden_state.shape)\n",
    "lhs_np=last_hidden_state.cpu().numpy()\n",
    "print(type(lhs_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a8da70",
   "metadata": {},
   "source": [
    "What we really want are hidden states across the whole dataset. For this, we can use the ```DatasetDict.map``` function again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "269ede43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    # place model inputs on the right device\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "    \n",
    "    # extract last hidden states\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    \n",
    "    # return vector for [CLS] token\n",
    "    return {\"hidden_state\" : last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f60062d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a928bf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf3018fd30948e297854d72e21968bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14afb51416da42c597c124afc36da8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5828cdc320af4e418082b1568a60da2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaa515f",
   "metadata": {},
   "source": [
    "**Create feature matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "adf227a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (16000, 768), X_valid shape : (2000, 768)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
    "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
    "\n",
    "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
    "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
    "\n",
    "print(f\"X_train shape : {X_train.shape}, X_valid shape : {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89c28b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.633"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=3000)\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
