{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4900a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e57c771",
   "metadata": {},
   "source": [
    "# Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5a55ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\amrul\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\emotion\\348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705 (last modified on Fri Mar 18 22:16:45 2022) since it couldn't be found locally at emotion., or remotely on the Hugging Face Hub.\n",
      "Using custom data configuration default\n",
      "Reusing dataset emotion (C:\\Users\\amrul\\.cache\\huggingface\\datasets\\emotion\\default\\0.0.0\\348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca93c372f1f345328c7ffdf1226699ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emotions=load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64485c80",
   "metadata": {},
   "source": [
    "   # Import Tokenizer and DistilBert model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd43118",
   "metadata": {},
   "source": [
    "It is important to use the right pretrained tokenizer for a pretrained model. Otherwise pretrained token representations become obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda34857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca432d7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# We will use DistilBERT which is smaller version of BERT to classify emotion text\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\amrul\\pycharmprojects\\transformers\\venvpy\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:546\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\amrul\\pycharmprojects\\transformers\\venvpy\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1724\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1724\u001b[0m         resolved_vocab_files[file_id] \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m   1736\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m local_files_only:\n",
      "File \u001b[1;32mc:\\users\\amrul\\pycharmprojects\\transformers\\venvpy\\lib\\site-packages\\transformers\\file_utils.py:1921\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   1917\u001b[0m     local_files_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m   1920\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m-> 1921\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1927\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1928\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[0;32m   1933\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[1;32mc:\\users\\amrul\\pycharmprojects\\transformers\\venvpy\\lib\\site-packages\\transformers\\file_utils.py:2177\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   2171\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   2172\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find the requested files in the cached path and outgoing traffic has been\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2173\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m disabled. To enable model look-ups and downloads online, set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2174\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2175\u001b[0m                 )\n\u001b[0;32m   2176\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2178\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2179\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2180\u001b[0m                 )\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;66;03m# From now on, etag is not None.\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_download:\n",
      "\u001b[1;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "# We will use DistilBERT which is smaller version of BERT to classify emotion text\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c2f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38305d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96fb58",
   "metadata": {},
   "source": [
    "Above we are checking if GPU is available. If not we are loading the model to CPU device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed1259",
   "metadata": {},
   "source": [
    "To warm up let's extract the last hidden states for a simple string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47a3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenization is an important step in building NLP models\"\n",
    "tokens=tokenizer.encode(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd05a2d0",
   "metadata": {},
   "source": [
    "```return_tensors=\"pt\"``` ensures that we return token embeddings as PyTorch tensors and we load them into the same device as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376d1cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc68656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(101) [CLS]\n",
      "tensor(1045) i\n",
      "tensor(2175) go\n",
      "tensor(2000) to\n",
      "tensor(2147) work\n",
      "tensor(2296) every\n",
      "tensor(2154) day\n",
      "tensor(102) [SEP]\n"
     ]
    }
   ],
   "source": [
    "def view_tokens(tokenizer,tokens):\n",
    "    for token in tokens:\n",
    "        print(token,tokenizer.decode(token))\n",
    "\n",
    "view_tokens(tokenizer,tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78743f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=model(tokens)\n",
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2664e6",
   "metadata": {},
   "source": [
    "Looking at the hidden states we can see it has the shape ```[batch_size,n_tokens,hid_dim]```. BERT generates a hidden state for each input token. Then it uses these hidden states to predict masked tokens. For classification tasks it is common to use the hidden state of [CLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c40cc",
   "metadata": {},
   "source": [
    "# Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada0506",
   "metadata": {},
   "source": [
    "```padding``` will pad each sequence with zeroes to the longest sequence in the batch. ```truncation``` will truncate at model's maximum context size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e020b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tokenizer,batch):\n",
    "    return tokenizer(batch[\"text\"],padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5890ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102], [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(tokenizer,emotions[\"train\"][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad95c5b",
   "metadata": {},
   "source": [
    "Above you will notice that batch tokenizer returns ```attention_masks``` in addition to ```input_ids```. This is necessary so that the model doesn't get confused with paddings and can ignore them when processing each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecb49422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c18e4ef668046d1adea7cc36a0a9c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349cbb1fe5ce4e2fae2231a1abc81c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62c9ac279f9423bb047c1f3a6aad946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_encoded=emotions.map(lambda batch : tokenize(tokenizer,batch),batched=True,batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace1029",
   "metadata": {},
   "source": [
    "By default ```DatasetDict.map``` operates on operates individually on every example in the corpus, so setting ```batched=True``` will encode the tweets in batches, while ```batch_size=None``` applies ```tokenize``` in one single batch and ensures that input tensors and attention masks have the same shape globally. We can confirm that this operation added two new features to the dataset ```input_ids``` and ```attention_masks```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c6bf913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_encoded[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e77be",
   "metadata": {},
   "source": [
    "We can pass ```input_ids``` and ```attention_mask``` to the model in a below manner if we had single example. Notice we have to convert them into PyTorch tensors before passing them into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "097bca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 87, 768])\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_set=emotions_encoded[\"train\"]\n",
    "train_set.features\n",
    "input_ids=train_set['input_ids']\n",
    "attention_mask=train_set[\"attention_mask\"]\n",
    "with torch.no_grad():\n",
    "    output=model(torch.tensor(input_ids[:5]),torch.tensor(attention_mask[:5]))\n",
    "last_hidden_state=output.last_hidden_state\n",
    "print(last_hidden_state.shape)\n",
    "lhs_np=last_hidden_state.cpu().numpy()\n",
    "print(type(lhs_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a8da70",
   "metadata": {},
   "source": [
    "What we really want are hidden states across the whole dataset. For this, we can use the ```DatasetDict.map``` function again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "269ede43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(batch):\n",
    "    input_ids=torch.tensor(batch[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(batch[\"attention_mask\"]).to(device)\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state=model(input_ids,attention_mask).last_hidden_state\n",
    "        last_hidden_state = last_hidden_state.cpu().numpy()\n",
    "    \n",
    "    # Use average of unmasked hidden states for classification\n",
    "    lhs_shape = last_hidden_state.shape\n",
    "    boolean_mask = ~np.array(batch[\"attention_mask\"]).astype(bool)\n",
    "    boolean_mask = np.repeat(boolean_mask,lhs_shape[-1], axis=-1)\n",
    "    boolean_mask = boolean_mask.reshape(lhs_shape)\n",
    "    masked_mean = np.ma.array(last_hidden_state,mask=boolean_mask).mean(axis=-1)\n",
    "    batch[\"hidden_state\"]=masked_mean.data\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cf34aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9ce9a45d594c70b4d61e652d2f9c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a12a0959a9401184f2a03b55bec671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68124575eb94d0d9d69f692c661f0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_encoded = emotions_encoded.map(forward_pass, batched=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d744096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
